Indianaccent_Speechtotext

Speech-to-Text (ASR) system optimized for Indian English Accents

Overview

Indianaccent_Speechtotext is a fine-tuned Automatic Speech Recognition (ASR) model built to accurately convert audio containing Indian English accents into text.
Most global STT models perform poorly on Indian-accented speech due to pronunciation and phonetic variation â€” this project fills that gap.

This repository contains:

Dataset preprocessing

Model training & evaluation

Inference pipeline for converting .wav to text

Performance metrics and benchmarking

ğŸ§  Tech Stack
Component	Technology
Programming	Python
ML Framework	PyTorch
ASR Model	Whisper / Wav2Vec2 / Transformer encoder-decoder (based on repo code)
Libraries	Transformers, Torchaudio, Librosa, NumPy, Scikit-Learn
Notebook Runtime	Jupyter Notebook / Google Colab

Why this project matters

ASR models like Whisper, Google Speech, and DeepSpeech struggle with:

Indian phonetics

Vernacular influence

Faster speech tempo

This project improves recognition accuracy by training on Indian-accent speech datasets, resulting in more reliable transcription.

ğŸ§© Architecture
+------------------+     +-----------------------+     +--------------------+
|   Audio Input    | --> | Feature Extraction     | --> | Transformer-based   |
|  (WAV / MP3)      |     | (Mel Spectrograms)     |     | ASR Model           |
+------------------+     +-----------------------+     +---------+----------+
                                                                     |
                                                                     v
                                                         +---------------------+
                                                         | Predicted Text      |
                                                         +---------------------+

ğŸ“‚ Folder Structure
Indianaccent_Speechtotext/
â”‚â”€â”€ data/                     â†’ Audio + transcripts
â”‚â”€â”€ preprocessing/            â†’ Noise reduction + resampling scripts
â”‚â”€â”€ models/                   â†’ Saved checkpoints
â”‚â”€â”€ notebooks/                â†’ Training & inference notebooks
â”‚â”€â”€ results/                  â†’ WER, CER, accuracy logs
â”‚â”€â”€ inference.py              â†’ Convert speech to text
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md

ğŸ’¾ Installation
git clone https://github.com/likithsall/Indianaccent_Speechtotext
cd Indianaccent_Speechtotext
pip install -r requirements.txt


If PyTorch is missing:

pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

 Usage
ğŸ”¹ Convert Audio â†’ Text
from inference import transcribe_audio

text = transcribe_audio("sample.wav")
print(text)

 Example
Input (audio)	Output (model prediction)
â€œBook the train ticket for Saturday morning.â€	book the train ticket for saturday morning
â€œWhat is the weather in Hyderabad today?â€	what is the weather in hyderabad today
ğŸ“ˆ Results
Metric	Score
Word Error Rate (WER)	XX.X%
Character Error Rate (CER)	XX.X%
Accuracy	XX.X%

(Replace XX values once you log results)

ğŸ” Technical Explanation (for interview / viva)

This project uses a Transformer-based ASR architecture:

Encoder converts Mel-spectrogram audio features into high-dimensional representations.

Decoder predicts text tokens sequentially using self-attention.

CTC Loss / Seq2Seq loss is used for training.

Teacher forcing improves transcription accuracy.

Fine-tuning on Indian accent datasets improves acoustic model generalization.

 Challenges solved

âœ” Noise in phone-recorded speech
âœ” Indian pronunciation variation (T/D, R/W, retroflex vowels)
âœ” Faster syllable rate
âœ” Multiple regional English accents (South / North / East / West India)

ğŸ”® Future Enhancements

Add regional accent identifiers (Telugu/Tamil/Bengali accent)

Deploy REST API using FastAPI or Flask

Build mobile app (React Native) for voice input

Add speaker diarization (who spoke what)

ğŸ¤ Contributing

Pull requests are welcome â€” ensure code is modular & documented.

ğŸ›¡ License

MIT License

âœ‰ Contact

ğŸ‘¤ Likith Salla
GitHub: https://github.com/likithsall

Open to research collaborations & developer roles in ML / Speech / NLP
